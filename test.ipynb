{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebfe616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import sparse\n",
    "from lib import *\n",
    "from classes import *\n",
    "from lightfm import LightFM\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ff5974",
   "metadata": {},
   "outputs": [],
   "source": [
    "users, orgs, reviews = get_data('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ea76a4-77d3-4a41-ae10-cade118f67e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_r, test_r = train_test_split(reviews, 1116)\n",
    "X_test, y_test = process_reviews(test_r)\n",
    "g = 1110\n",
    "train_r1, train_r2 = train_r[train_r['ts'] <= g], train_r[train_r['ts'] > g]\n",
    "CNT_TOP = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcee96ed-4b7e-4651-8a0b-9f4bb0103cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from pandas.util import hash_pandas_object\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRanker, Pool, MetricVisualizer\n",
    "import pickle\n",
    "\n",
    "def predict_to_pandas(predictions):\n",
    "    train_b = []\n",
    "    for i, r in tqdm(predictions.iterrows()):\n",
    "        for ic, org_id in enumerate(r['target']):\n",
    "            train_b.append([r['user_id'], org_id, ic + 1])\n",
    "    \n",
    "    train_b = pd.DataFrame(train_b, columns=['user_id', 'org_id', 'pos_lfm'])\n",
    "    return train_b\n",
    "\n",
    "def get_comb_top_orgs(_users, prediction, k_r):\n",
    "    users_uq = pd.DataFrame(prediction['user_id'].unique(), columns=['user_id'])\n",
    "    users = _users.merge(users_uq, on='user_id', how='right')\n",
    "    k_r_msk = k_r[k_r['user_city'] == 'msk'][['org_id', 'rating']]\n",
    "    top_orgs_msk = k_r_msk.groupby(by='org_id').count().reset_index().sort_values(by='rating', ascending=False)[['org_id']][:CNT_TOP]\n",
    "    users_msk = users[users['city'] == 'msk'][['user_id']]\n",
    "    komb_msk = users_msk.merge(top_orgs_msk, how='cross')\n",
    "\n",
    "    k_r_spb = k_r[k_r['user_city'] == 'spb'][['org_id', 'rating']]\n",
    "    top_orgs_spb = k_r_spb.groupby(by='org_id').count().reset_index().sort_values(by='rating', ascending=False)[['org_id']][:CNT_TOP]\n",
    "    users_spb = users[users['city'] == 'spb'][['user_id']]\n",
    "    komb_spb = users_spb.merge(top_orgs_spb, how='cross')\n",
    "    return pd.concat([komb_msk, komb_spb])\n",
    "\n",
    "def pred_to_proc(_users, _orgs, _predictions, r1, r2, topklfm):\n",
    "    users = _users.copy()\n",
    "    orgs = _orgs.copy()\n",
    "    predictions = _predictions.copy()\n",
    "\n",
    "    print(\"Proc creating... \", end=\"\")\n",
    "\n",
    "    r = pd.concat([r1, r2])\n",
    "    t_r = r[r['user_city'] != r['org_city']]\n",
    "    k_r = t_r[t_r['rating'] >= 4]\n",
    "\n",
    "    komb = get_comb_top_orgs(users, predictions, k_r[['org_id', 'user_city', 'rating']])\n",
    "    predictions = predictions.merge(komb, on=['user_id', 'org_id'], how='outer')\n",
    "    predictions['pos_lfm'] = predictions['pos_lfm'].fillna(topklfm + 1)\n",
    "    proc = predictions.merge(r2[['user_id', 'org_id', 'rating']], on=['user_id', 'org_id'], how='left')\n",
    "    proc['rating'] = proc['rating'].fillna(0)\n",
    "    proc = proc.merge(users[['user_id', 'city']], on=['user_id']).rename(columns={'city': 'user_city'})\n",
    "    orgs = orgs.merge(k_r[['org_id', 'rating']].groupby(by=\"org_id\").count().rename(columns={'rating':'cnt_pos'}), on=\"org_id\", how='left')\n",
    "    orgs['cnt_pos'] = orgs['cnt_pos'].fillna(0)\n",
    "    proc = proc.merge(orgs[['org_id', 'cnt_pos']], on=['org_id'])\n",
    "    proc = proc.sort_values(by=['user_id'])\n",
    "\n",
    "    print(\"Finish\")\n",
    "    \n",
    "    return proc\n",
    "\n",
    "class CatBoostSolver:\n",
    "    def __init__(self, users, orgs):\n",
    "        self.users = users.copy()\n",
    "        self.orgs = orgs.copy()\n",
    "        self.org_ctoi, self.org_itoc = create_mappings(self.orgs['org_id'])\n",
    "        self.user_ctoi, self.user_itoc = create_mappings(self.users['user_id'])\n",
    "        self.users['user_id'] = self.users['user_id'].map(self.user_ctoi)\n",
    "        self.orgs['org_id'] = self.orgs['org_id'].map(self.org_ctoi)\n",
    "    \n",
    "    def fit(self, _r1, _r2, topklfm=100, test_size=0.5):\n",
    "        self.topklfm = topklfm\n",
    "        \n",
    "        r1 = _r1.copy()\n",
    "        r2 = _r2.copy()\n",
    "        r1['user_id'] = r1['user_id'].map(self.user_ctoi)\n",
    "        r2['user_id'] = r2['user_id'].map(self.user_ctoi)\n",
    "        r1['org_id'] = r1['org_id'].map(self.org_ctoi)\n",
    "        r2['org_id'] = r2['org_id'].map(self.org_ctoi)\n",
    "        self.r1 = r1\n",
    "        self.r2 = r2\n",
    "\n",
    "        arg_hash = str(abs(hash_pandas_object(r1[['user_id', 'org_id']]).sum() ^ hash_pandas_object(r2[['user_id', 'org_id']]).sum() ^ topklfm))\n",
    "\n",
    "        path_lfm = 'tmp/lmf_' + arg_hash + '.pkl'\n",
    "        if os.path.exists(path_lfm):\n",
    "            with open(path_lfm, 'rb') as f:\n",
    "                self.lfm, lfm_predictions = pickle.load(f)\n",
    "        else:\n",
    "            self.lfm = SplitLightFMSolver(self.users, self.orgs)\n",
    "            self.lfm.fit(r1, min_pos_rating=5)\n",
    "            self.lfm.fit_partial(5)\n",
    "            lfm_predictions = self.lfm.predict(pd.DataFrame(r2['user_id'].unique(), columns=['user_id']), topk=topklfm)\n",
    "            with open(path_lfm, 'wb') as f:\n",
    "                pickle.dump((self.lfm, lfm_predictions), f)\n",
    "\n",
    "        path_train = 'tmp/train_' + arg_hash + '.csv'\n",
    "        if (os.path.exists(path_train)):\n",
    "            lfm_predictions_pd = pd.read_csv(path_train)\n",
    "        else:\n",
    "            lfm_predictions_pd = predict_to_pandas(lfm_predictions)\n",
    "            lfm_predictions_pd.to_csv(path_train, index=False)\n",
    "        \n",
    "        path_proc = 'tmp/proc_' + arg_hash + '.csv'\n",
    "        if (os.path.exists(path_proc)):\n",
    "            proc = pd.read_csv(path_proc)\n",
    "        else:\n",
    "            proc = pred_to_proc(self.users, self.orgs, lfm_predictions_pd, r1, r2, topklfm)\n",
    "            proc.to_csv(path_proc, index=False)\n",
    "        \n",
    "\n",
    "        print(\"Pools creating... \", end=\"\")\n",
    "        self.features_to_catboost = ['user_city', 'pos_lfm', 'cnt_pos']\n",
    "        self.cat_features = [0]\n",
    "        \n",
    "        user_id = proc['user_id'].unique()\n",
    "        user_id_train, user_id_test = train_test_split(user_id, test_size=test_size, random_state=42, shuffle=False)\n",
    "        proc_train, proc_test = proc[proc['user_id'].isin(user_id_train)], proc[proc['user_id'].isin(user_id_test)]\n",
    "        X_train, y_train, group_id_train = proc_train[self.features_to_catboost].values, proc_train['rating'].values, proc_train['user_id'].values\n",
    "        X_test, y_test, group_id_test = proc_test[self.features_to_catboost].values, proc_test['rating'].values, proc_test['user_id'].values\n",
    "        y_train = 1*(y_train >= 4)\n",
    "        y_test = 1*(y_test >= 4)\n",
    "        \n",
    "        self.train = Pool(\n",
    "            data=X_train,\n",
    "            label=y_train,\n",
    "            group_id=group_id_train,\n",
    "            cat_features=self.cat_features\n",
    "        )\n",
    "        \n",
    "        if test_size > 0:\n",
    "            self.test = Pool(\n",
    "                data=X_test,\n",
    "                label=y_test,\n",
    "                group_id=group_id_test,\n",
    "                cat_features=self.cat_features\n",
    "            )\n",
    "        print(\"Finish\")\n",
    "        \n",
    "        self.model = CatBoostRanker(\n",
    "            loss_function='YetiRankPairwise',\n",
    "            learning_rate=0.05,\n",
    "            depth=6,\n",
    "            min_data_in_leaf=80,\n",
    "            eval_metric='MAP:top=20',\n",
    "            train_dir='tmp/f_'+arg_hash,\n",
    "            verbose=False,\n",
    "            random_seed=42,\n",
    "            iterations=1000,\n",
    "            # thread_count=-1\n",
    "            task_type='GPU'\n",
    "        )\n",
    "        \n",
    "        if test_size > 0:\n",
    "            self.model.fit(self.train, eval_set=self.test, verbose=True)\n",
    "        else:\n",
    "            self.model.fit(self.train, verbose=True)\n",
    "\n",
    "    def predict(self, _X_test, path=None, topk=N): \n",
    "        X_test = _X_test.copy()\n",
    "        X_test['user_id'] = X_test['user_id'].map(self.user_ctoi)\n",
    "\n",
    "        lfm_predictions = self.lfm.predict(X_test, topk=self.topklfm)\n",
    "        lfm_predictions_pd = predict_to_pandas(lfm_predictions)\n",
    "        proc = pred_to_proc(self.users, self.orgs, lfm_predictions_pd, self.r1, self.r2, self.topklfm)\n",
    "        proc['rating'] = self.model.predict(proc[self.features_to_catboost].values, verbose=True)\n",
    "        \n",
    "        def f(x):\n",
    "            a = x['org_id']\n",
    "            b = x['rating']\n",
    "            return list(np.vectorize(lambda x : self.org_itoc[x])(np.array(a)[np.argsort(b)[::-1][:topk]]))\n",
    "\n",
    "        fp = proc[['user_id', 'org_id', 'rating']].groupby(by='user_id').agg(lambda x: list(x)).reset_index()\n",
    "        fp['target'] = fp.progress_apply(f, axis=1)\n",
    "        predictions = fp[['user_id', 'target']].copy()\n",
    "        predictions['user_id'] = predictions['user_id'].map(self.user_itoc)\n",
    "        if path != None:\n",
    "            save_predictions_to_file(predictions, path)\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ccecdf-82f1-4ae4-bd6a-444de6c4e5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = CatBoostSolver(users, orgs)\n",
    "ct.fit(train_r1, train_r2, 30, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227d40dd-22db-489b-9e2c-65e56476fc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ct.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6476ff5-cc40-4c96-bb4f-e530e7565fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_score(MNAP_N(y_test, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b69bbb8-4acf-40fd-92b4-3680ebcb4b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.model.get_feature_importance(data=ct.test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users = pd.read_csv('data/test_users.csv')\n",
    "ct.predict(test_users, \"answers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db971ff380b731045e1ce400ae72ff5111e81ffd3e9c4b9122002f711e089e2d"
  },
  "jupytercloud": {
   "vault": {
    "secrets": [
     {
      "name": "yt_secrets",
      "uuid": "sec-01fd5qjpw0xwwpv6t83wc41tp8"
     }
    ]
   }
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('py_env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
